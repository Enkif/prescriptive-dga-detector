Prescriptive DGA Detector
This project implements an end-to-end Python pipeline for detecting Domain Generation Algorithm (DGA) domains, explaining the model's decision, and automatically generating a prescriptive incident response playbook. It leverages H2O AutoML for high-performance classification, SHAP for model interpretability, and Google Generative AI for actionable insights.

Project Goal
The primary objective is to move beyond simple "black box" model predictions in cybersecurity. While accurate DGA detection is crucial, understanding why a domain is flagged and receiving immediate, context-aware guidance significantly enhances an analyst's ability to respond effectively. This pipeline aims to bridge the gap between detection, explanation, and automated response.

Architecture
The system is designed in three distinct, interconnected stages:

Model Training & Export (H2O AutoML):

Purpose: Rapidly builds and optimizes a DGA classification model.

Technology: H2O's AutoML framework.

Output: A highly accurate DGA detection model exported as a MOJO (Model Optimized, Java Optimized) file.

Prediction & Explanation (SHAP):

Purpose: Takes an input domain, predicts its class (legitimate/DGA), and if DGA, explains the decision.

Technology: H2O MOJO runtime for prediction, SHAP (SHapley Additive exPlanations) for local interpretability.

Output: A clear prediction, and for DGA domains, a detailed breakdown of feature contributions to that prediction.

Prescriptive Analytics (Google Generative AI - Gemini):

Purpose: Translates the model's explanation (SHAP findings) into an actionable incident response playbook.

Technology: Google Generative AI (Gemini model).

Output: A step-by-step guide for cybersecurity analysts to investigate and mitigate the DGA threat.

The XAI-to-GenAI Bridge
A critical component of this architecture is the "XAI-to-GenAI Bridge." This programmatic layer interprets the numerical SHAP values generated for a specific DGA prediction. It transforms these raw insights into a structured, human-readable summary of the key features that influenced the model's decision. This dynamic summary is then passed as context to the Google Generative AI model, enabling it to generate a highly relevant and precise incident response playbook.

Setup and Usage
Prerequisites
Python 3.8+

pip (Python package installer)

Installation
Clone the Repository:

git clone https://github.com/Enkif/prescriptive-dga-detector.git 
cd prescriptive-dga-detector

Install Dependencies:

pip install -r requirements.txt

Step-by-Step Usage
Step 1: Train and Export the DGA Detection Model
This script will generate a synthetic training dataset, train an H2O AutoML model, and export the best-performing model as a MOJO file (DGA_Leader.zip) into the ./model directory.

python 1_train_and_export.py

Expected Output: We will see H2O initialization messages, dataset generation progress, AutoML training logs, and finally, confirmation that the MOJO model has been saved to ./model/DGA_Leader.zip.

Step 2: Analyze a Domain and Generate a Playbook
This is the main application. It takes a domain name as a command-line argument, predicts its class, and if it's a DGA, provides a SHAP explanation and a generative AI-powered incident response playbook.

GEMINI_API_KEY = "GEMINI_API_KEY_HERE" 

To analyze a domain:

python 2_analyze_domain.py --domain <domain-name-here>

Example (likely DGA domain from synthetic data):

python 2_analyze_domain.py --domain y8z5q1x3n9m2k7.info

Example likely legitimate domain

python 2_analyze_domain.py --domain example.com

Expected Output:

For a DGA domain: We will see the predicted class (DGA), the DGA probability, a SHAP explanation detailing feature contributions (length, entropy), and a generated incident response playbook.

For a legitimate domain: We will see the predicted class (Legitimate) and a message indicating no SHAP explanation or playbook is generated.

Model and Data
model/DGA_Leader.zip: This directory contains the exported H2O MOJO model, which is the result of running 1_train_and_export.py.

dga_dataset_train.csv: A synthetic dataset generated by 1_train_and_export.py for model training.

Documentation
README.md: (This file) Provides an overview of the project, its architecture, setup, and usage instructions.

TESTING.md: Contains detailed manual verification steps for the pipeline.

Automation
.github/workflows/lint.yml: Includes a GitHub Actions workflow for static code analysis (linting) using Flake8. This ensures code quality and consistency.
